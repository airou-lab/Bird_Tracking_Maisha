# -*- coding: utf-8 -*-
"""python bird.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FcfvjCkPTJ8IFDwt3_xr__cuVg1-RYKi
"""

import cv2
import matplotlib.pyplot as plt

from ultralytics import YOLO
import random
import cv2
import numpy as np



model = YOLO("yolov8m-seg.pt")
img1 = cv2.imread("/home/airlab/Videos/GoPro/15.png")

# if you want all classes
yolo_classes = list(model.names.values())
classes_ids = [yolo_classes.index(clas) for clas in yolo_classes]

conf = 0.5

results = model.predict(img1, conf=conf)
colors = [random.choices(range(256), k=3) for _ in classes_ids]
for result in results:
    for mask, box in zip(result.masks.xy, result.boxes):
        if box.cls == 14:
          points = np.int32([mask])
          color_number = classes_ids.index(int(box.cls[0]))
          #cv2.fillPoly(img1, points, colors[color_number])

cv2.imshow("image",img1)
cv2.waitKey(0)


stencil = np.zeros(img1.shape).astype(img1.dtype)
color = [255, 255, 255]
cv2.fillPoly(stencil, points, color)
result1 = cv2.bitwise_and(img1, stencil)
cv2.imshow("image1",result1)
cv2.waitKey(0)

img2 = cv2.imread("/home/airlab/Videos/GoPro/16.png")

# if you want all classes
yolo_classes = list(model.names.values())
classes_ids = [yolo_classes.index(clas) for clas in yolo_classes]

conf = 0.5

results = model.predict(img2, conf=conf)
colors = [random.choices(range(256), k=3) for _ in classes_ids]
for result in results:
    for mask, box in zip(result.masks.xy, result.boxes):
      if box.cls == 14:
        points = np.int32([mask])

cv2.imshow("image2",img2)
cv2.waitKey(0)

stencil = np.zeros(img2.shape).astype(img2.dtype)
color = [255, 255, 255]
cv2.fillPoly(stencil, points, color)
result2 = cv2.bitwise_and(img2, stencil)
cv2.imshow("image3",result2)
cv2.waitKey(0)

#sift
sift = cv2.xfeatures2d.SIFT_create()

keypoints_1, descriptors_1 = sift.detectAndCompute(result1,None)
keypoints_2, descriptors_2 = sift.detectAndCompute(result2,None)

# Create a BFMatcher object
bf = cv2.BFMatcher()

# Find matches using KNN
matches = bf.knnMatch(descriptors_1, descriptors_2, k=2)

all_matches = [m[0] for m in matches]
img_all_matches = cv2.drawMatches(img1, keypoints_1, img2, keypoints_2, all_matches, None, flags=2)
plt.imshow(img_all_matches), plt.title("All Matches Before Filtering")
plt.show()

# Camera matrix (from your calibration data)
K = np.array([[2.47313196e+03, 0.00000000e+00, 2.78379536e+03],
              [0.00000000e+00, 2.45870179e+03, 2.41120292e+03],
              [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])

# Apply Lowe's ratio test
good_matches = []
for m, n in matches:
    if m.distance < 0.85 * n.distance:
        good_matches.append(m)
        


# Ensure there are enough good matches to proceed, The code begins by checking if there are enough "good matches" between keypoints in two images. This is a common strategy to filter out unreliable matches.
if len(good_matches) > 8:
    points1 = np.float32([keypoints_1[m.queryIdx].pt for m in good_matches])
    points2 = np.float32([keypoints_2[m.trainIdx].pt for m in good_matches]) #It extracts the 2D coordinates of matched keypoints from both images.

    # Find fundamental matrix using RANSAC, it uses RANSAC to find the fundamental matrix (F) that describes the geometric relationship between the two images.
    F, mask = cv2.findFundamentalMat(points1, points2, cv2.FM_RANSAC)

    # Check if a valid fundamental matrix was found
    if F is not None and F.shape == (3, 3) and mask is not None: #It checks if a valid fundamental matrix was found.
        points1 = points1[mask.ravel() == 1]
        points2 = points2[mask.ravel() == 1]   #for removing outliers, It removes outliers based on the RANSAC mask

        # Find essential matrix
        E = K.T @ F @ K  #calibration(transpose). elementwise dot. fundamental matrix. calibration #It calculates the essential matrix (E) using the camera calibration matrix (K).

        # Recover pose
        _, R, t, mask_pose = cv2.recoverPose(E, points1, points2, K) #It recovers the relative pose (rotation matrix R and translation vector t) between the two cameras.

        
        img_matches = cv2.drawMatches(img1, keypoints_1, img2, keypoints_2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

        # Triangulation, It performs triangulation to obtain 3D coordinates (points_3D) of the matched keypoints.
        P1 = np.hstack((np.eye(3, 3), np.zeros((3, 1))))
        P2 = np.hstack((R, t))
        points_4D_hom = cv2.triangulatePoints(P1, P2, points1.T, points2.T)
        points_3D = points_4D_hom / points_4D_hom[3]  # Convert to 3D

        # Display results, It visualizes the matching results and creates a 3D scatter plot of the reconstructed points.
        plt.imshow(img_matches), plt.show()

        # Print the 3D points
        print("3D Points:")
        for point in points_3D:
            print(point)


        # Visualize 3D points with equal axis scales
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')

        # Scatter plot
        ax.scatter(points_3D[:, 0], points_3D[:, 1], points_3D[:, 2], color='blue')


        # Set the aspect ratio to be equal
        max_range = np.array([points_3D[:, 0].max() - points_3D[:, 0].min(),
                              points_3D[:, 1].max() - points_3D[:, 1].min(),
                              points_3D[:, 2].max() - points_3D[:, 2].min()]).max() / 2.0

        mid_x = (points_3D[:, 0].max() + points_3D[:, 0].min()) * 0.5
        mid_y = (points_3D[:, 1].max() + points_3D[:, 1].min()) * 0.5
        mid_z = (points_3D[:, 2].max() + points_3D[:, 2].min()) * 0.5

        ax.set_xlim(mid_x - max_range, mid_x + max_range)
        ax.set_ylim(mid_y - max_range, mid_y + max_range)
        ax.set_zlim(mid_z - max_range, mid_z + max_range)

        ax.set_xlabel('X axis')
        ax.set_ylabel('Y axis')
        ax.set_zlabel('Z axis')

        plt.title("3D point cloud with equal axes")
        plt.show()

    else:
        print("Fundamental matrix computation failed.")
else:
    print("Not enough good matches to proceed.")


print("maisha")
